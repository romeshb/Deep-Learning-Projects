{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd0382f0e64cf403685c5be21edb594e4021614f4856902d04462be2693a08ed44b",
   "display_name": "Python 3.6.13 64-bit ('hand_detect': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0508 18:22:01.156567 12472 deprecation_wrapper.py:119] From e:\\AI\\Projects\\Traffic_Monitoring\\Final_app\\utils\\label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "importing done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Loading the requried libraries \"\"\"\n",
    "import cv2\n",
    "#from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date\n",
    "from utils import detector_utils as detector_utils\n",
    "from utils import visualization_utils as vis_util\n",
    "from utils import label_map_util\n",
    "#import argparse\n",
    "print('importing done') #loading the video stream"
   ]
  },
  {
   "source": [
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument('-d', '--display', dest='display', type=int,\n",
    "                        default=1, help='Display the detected images using OpenCV. This reduces FPS')\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "#detection_graph, sess = detector_utils.load_inference_graph()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category label\r\n",
    "TRAINED_MODEL_DIR = 'E:\\AI\\Projects\\Traffic_Monitoring\\Actual_app/frozen_graphs'\r\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\r\n",
    "PATH_TO_CKPT = TRAINED_MODEL_DIR + '/frozen_inference_graph.pb'\r\n",
    "# List of the strings that is used to add correct label for each box.\r\n",
    "PATH_TO_LABELS = TRAINED_MODEL_DIR + '/mscoco_label_map.pbtxt'\r\n",
    "\r\n",
    "NUM_CLASSES = 90\r\n",
    "# load label map using utils provided by tensorflow object detection api\r\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\r\n",
    "categories = label_map_util.convert_label_map_to_categories(\r\n",
    "    label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\r\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> ====== Loading frozen graph into memory\n",
      ">  ====== Inference graph loaded.\n"
     ]
    }
   ],
   "source": [
    "#Loading the model\n",
    "detection_graph, sess = detector_utils.load_inference_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'traffic_vid_2.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if camera opened successfully\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if (cap.isOpened()== False):\n",
    "  print(\"Error opening video stream or file\")\n",
    "    \n",
    "    # Used to calculate fps\n",
    "start_time = datetime.datetime.now()\n",
    "num_frames = 0\n",
    " \n",
    "# Read until video is completed\n",
    "while (cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = np.array(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Run image through tensorflow graph\n",
    "        boxes, scores, classes = detector_utils.detect_objects(frame, detection_graph, sess)\n",
    "        #calulate the FPS\n",
    "        num_frames += 1\n",
    "        elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "        fps = num_frames / elapsed_time\n",
    "\n",
    "        #Visualize boxes and labels\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array( frame,boxes, (np.int32(np.squeeze(classes))),scores,category_index, use_normalized_coordinates= True, line_thickness= 3)\n",
    "        \n",
    "        #Draw FPS on frame\n",
    "        detector_utils.draw_text_on_image(\"FPS : \" + str(\"{0:.2f}\".format(fps)), frame)\n",
    " \n",
    "        # Display the resulting frame\n",
    "        height, width = frame.shape[:2]\n",
    "        height = int(height*0.5)\n",
    "        width = int(width *0.5)\n",
    "        cv2.namedWindow('jpg', cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('jPG', width,height)\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imshow('jpg', frame)\n",
    "        #cv2.imshow('Frame', frame)\n",
    " \n",
    "        # Press 'Q' on keyboard to  exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    " \n",
    "    # Break the loop\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Print(\"Run next code to cancel the output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ]
}