{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Convolutional Neural Network\n#importing the libraries\nimport tensorflow as tf\n#from tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'2.4.1'"},"metadata":{}}]},{"cell_type":"code","source":"#Part 1 - Data Preprocessing\n#Part 1.a - Preprocessing the Training Set\ntrain_datagen = ImageDataGenerator(rescale = 1./255,shear_range=0.2,zoom_range=0.2, horizontal_flip= True)\ntraining_set = train_datagen.flow_from_directory('../input/cat-and-dog/training_set/training_set',target_size=(64, 64),batch_size= 32,class_mode=\"binary\")","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 8005 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"#Part 1.b - Preprocessing the Test Set\ntest_datagen = ImageDataGenerator(rescale = 1./255)\ntest_set = test_datagen.flow_from_directory('../input/cat-and-dog/test_set/test_set',target_size= (64,64), batch_size = 32, class_mode = 'binary')","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 2023 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"#Part 2, Building the CNN\n\n#initialising the CNN \ncnn = tf.keras.models.Sequential()\n\n#Part 2.a -Step 1 - Convolution\ncnn.add(tf.keras.layers.Conv2D(filters = 32,padding = 'same', kernel_size =3, activation = 'relu', input_shape = [64,64,3]))\n\n#Part 2.b - Step 2 - Pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides = 2))\n#Adding a second convolutional layer\ncnn.add (tf.keras.layers.Conv2D(filters = 32,padding = 'same', kernel_size =3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides = 2))\n\n#Part 2.c - Step 3 - Flattening\ncnn.add(tf.keras.layers.Flatten())\n#Part 2.d - Step 4 - Full Connection\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n\n#Part 2.e - Step 5 - Output Layer\ncnn.add(tf.keras.layers.Dense(units =1, activation ='sigmoid'))","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"cnn.summary()","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 64, 64, 32)        896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 8192)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               1048704   \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 1,058,977\nTrainable params: 1,058,977\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#Part 3 - Training the CNN\n# initialize tqdm callback with default parameters\nimport tensorflow_addons as tfa\ntqdm_callback = tfa.callbacks.TQDMProgressBar()\n\n# train the model with tqdm_callback\n# make sure to set verbose = 0 to disable\n# the default progress bar.\n\n#Part 3.a - Compiling the CNN\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics=['accuracy'])\n\n#Part 3.b - Training the CNN on the Training Set and Evaluating it on the Test Set.\ncnn.fit(x = training_set, validation_data= test_set,callbacks=tqdm_callback, epochs= 15)","metadata":{"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training:   0%|           0/15 ETA: ?s,  ?epochs/s","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7720c282b65e49b08c5fc1c01b535f52"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/15\nEpoch 1/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc953ec1283340b48d11bd6ee92c83a3"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 39s 152ms/step - loss: 0.6880 - accuracy: 0.5480 - val_loss: 0.6222 - val_accuracy: 0.6574\nEpoch 2/15\nEpoch 2/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e6ee2f258646a3be223436ba960e5e"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 39s 154ms/step - loss: 0.6031 - accuracy: 0.6727 - val_loss: 0.6005 - val_accuracy: 0.6856\nEpoch 3/15\nEpoch 3/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d5249a491945f7bfaf444d05fa57f5"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 39s 154ms/step - loss: 0.5780 - accuracy: 0.6977 - val_loss: 0.5626 - val_accuracy: 0.7173\nEpoch 4/15\nEpoch 4/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9937471029d747038172805e217814d8"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 38s 151ms/step - loss: 0.5296 - accuracy: 0.7343 - val_loss: 0.5211 - val_accuracy: 0.7548\nEpoch 5/15\nEpoch 5/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95d311ad10ce42059cfb50bc904a5fc8"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 38s 150ms/step - loss: 0.4925 - accuracy: 0.7490 - val_loss: 0.5159 - val_accuracy: 0.7469\nEpoch 6/15\nEpoch 6/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d46ebda1c12e41de90fe372abe80067d"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 37s 149ms/step - loss: 0.4798 - accuracy: 0.7646 - val_loss: 0.4907 - val_accuracy: 0.7657\nEpoch 7/15\nEpoch 7/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c268fee793b54b099a7fb7766639d2da"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 37s 145ms/step - loss: 0.4623 - accuracy: 0.7697 - val_loss: 0.4866 - val_accuracy: 0.7687\nEpoch 8/15\nEpoch 8/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23ed677cc459400093025b11ecd5f3a4"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 37s 149ms/step - loss: 0.4521 - accuracy: 0.7869 - val_loss: 0.4902 - val_accuracy: 0.7642\nEpoch 9/15\nEpoch 9/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76fad282097e44888de3795d4b5e3058"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 37s 146ms/step - loss: 0.4236 - accuracy: 0.8075 - val_loss: 0.4762 - val_accuracy: 0.7766\nEpoch 10/15\nEpoch 10/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c409f24830648b4b84465ca1d6619bf"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 37s 146ms/step - loss: 0.4018 - accuracy: 0.8102 - val_loss: 0.5027 - val_accuracy: 0.7677\nEpoch 11/15\nEpoch 11/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c6ddaf7610d4752a5fa3e43527a886b"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 37s 146ms/step - loss: 0.3967 - accuracy: 0.8148 - val_loss: 0.4967 - val_accuracy: 0.7657\nEpoch 12/15\nEpoch 12/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1449e7b8697f4014a3e0929366bd3e19"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 37s 146ms/step - loss: 0.3939 - accuracy: 0.8228 - val_loss: 0.5002 - val_accuracy: 0.7692\nEpoch 13/15\nEpoch 13/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a0d0f975bff4f91b6386460b0224126"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 36s 145ms/step - loss: 0.3726 - accuracy: 0.8353 - val_loss: 0.5021 - val_accuracy: 0.7790\nEpoch 14/15\nEpoch 14/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"351ac2296a40400abd838aea1108c0ce"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 36s 145ms/step - loss: 0.3585 - accuracy: 0.8370 - val_loss: 0.4669 - val_accuracy: 0.7998\nEpoch 15/15\nEpoch 15/15\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/251           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d2d864f83354a9594a0b5f7e1390274"}},"metadata":{}},{"name":"stdout","text":"251/251 [==============================] - 37s 148ms/step - loss: 0.3446 - accuracy: 0.8438 - val_loss: 0.5301 - val_accuracy: 0.7860\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fa31aabeb50>"},"metadata":{}}]},{"cell_type":"code","source":"#save it as a h5 file\nfrom tensorflow.keras.models import load_model\ncnn.save('model_rcat_dog.h5')","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#load model\nfrom tensorflow.keras.models import load_model\nmodel = load_model('model_rcat_dog.h5')","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 64, 64, 32)        896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 8192)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               1048704   \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 1,058,977\nTrainable params: 1,058,977\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#Part 4 - Making a single Prediction\n\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\n#Testing with a different dataset from kaggle of Cat and dog.\ntest_image = image.load_img('../input/cat2dog/cat2dog/testB/1095.jpg',target_size =(64,64))\ntest_image = image.img_to_array(test_image)\ntest_image = test_image/255\ntest_image = np.expand_dims(test_image, axis =0)\nresult = cnn.predict(test_image)","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"result[0][0]","metadata":{"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0.9986966"},"metadata":{}}]},{"cell_type":"code","source":"if result[0][0]<=0.5:\n    print(\"The image classified is cat\")\nelse:\n    print(\"The image classified is dog\")","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"The image classified is dog\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> ****End of Project****","metadata":{}},{"cell_type":"markdown","source":"****Now we download the model file in .h5 extension.****","metadata":{}},{"cell_type":"code","source":"import os\nos.listdir('/kaggle/working/')","metadata":{"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['__notebook_source__.ipynb', 'model_rcat_dog.h5']"},"metadata":{}}]},{"cell_type":"code","source":"os.chdir(r'/kaggle/working')","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'model_rcat_dog.h5')","metadata":{"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model_rcat_dog.h5","text/html":"<a href='model_rcat_dog.h5' target='_blank'>model_rcat_dog.h5</a><br>"},"metadata":{}}]}]}